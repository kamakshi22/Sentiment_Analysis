{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kamakshibansal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kamakshibansal/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary1= pd.read_csv(\"/Users/kamakshibansal/dictionary.csv\")\n",
    "File1= pd.read_csv(\"/Users/kamakshibansal/Downloads/File1.csv\")\n",
    "File2= pd.read_csv(\"/Users/kamakshibansal/Downloads/File2.csv\")\n",
    "File3= pd.read_csv(\"/Users/kamakshibansal/Downloads/File3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in '/Users/kamakshibansal/nltk_data/corpora/stopwords'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>feedback</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sub-category</th>\n",
       "      <th>SurveyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Category</td>\n",
       "      <td>I got my order vey fast,the day after i placed...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Product quality</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General</td>\n",
       "      <td>XXX  is amazing...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                           feedback sentiment  \\\n",
       "0  Category  I got my order vey fast,the day after i placed...  Positive   \n",
       "1   General                                 XXX  is amazing...  Positive   \n",
       "\n",
       "      sub-category SurveyName  \n",
       "0  Product quality          C  \n",
       "1              NaN          C  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dictionary1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary1['feedback'] = Dictionary1['feedback'].str.strip()\n",
    "# Dictionary1['feedback'].head()\n",
    "Dictionary1.feedback = Dictionary1.feedback.replace('\\s+', ' ', regex=True)\n",
    "File1.feedback = File1.feedback.replace('\\s+', ' ', regex=True)\n",
    "File2.feedback = File2.feedback.replace('\\s+', ' ', regex=True)\n",
    "File3.feedback = File3.feedback.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary1['feedback'].to_csv(\"A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filedict = pd.DataFrame()\n",
    "Filedict[\"feedback\"]= Dictionary1[\"feedback\"]\n",
    "Filedict[\"sentiment\"]= Dictionary1[\"sentiment\"]\n",
    "Filedict.to_csv(\"rat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "File11 = pd.DataFrame()\n",
    "File11[\"feedback\"]= File1[\"feedback\"]\n",
    "File11[\"sentiment\"]= File1[\"sentiment\"]\n",
    "File11.to_csv(\"rat2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "File22 = pd.DataFrame()\n",
    "File22[\"feedback\"]= File2[\"feedback\"]\n",
    "File22[\"sentiment\"]= File2[\"Sentiment\"]\n",
    "File22.to_csv(\"rat3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "File33 = pd.DataFrame()\n",
    "File33[\"feedback\"]= File3[\"feedback\"]\n",
    "File33[\"sentiment\"]= File3[\"sentiment\"]\n",
    "File33.to_csv(\"rat4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Dict=pd.concat([Filedict, File11,File22, File33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Dict.to_csv(\"New_Dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127072, 2)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Dict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I got my order vey fast,the day after i placed...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XXX is amazing...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The delivery was on time.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I m really happy with this early delivery and ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Early morning... Ordered at night and next day...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            feedback sentiment\n",
       "0  I got my order vey fast,the day after i placed...  Positive\n",
       "1                                  XXX is amazing...  Positive\n",
       "2                          The delivery was on time.  Positive\n",
       "3  I m really happy with this early delivery and ...  Positive\n",
       "4  Early morning... Ordered at night and next day...  Positive"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Dict.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MReport1= pd.read_csv(\"/Users/kamakshibansal/Downloads/MReport1.csv\")\n",
    "MReport2= pd.read_csv(\"/Users/kamakshibansal/Downloads/MReport2.csv\")\n",
    "MReport3= pd.read_csv(\"/Users/kamakshibansal/Downloads/MReport3.csv\")\n",
    "MReport4= pd.read_csv(\"/Users/kamakshibansal/Downloads/MReport4.csv\")\n",
    "MReport5= pd.read_csv(\"/Users/kamakshibansal/Downloads/MReport5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "MReport1.feedback = MReport1.feedback.replace('\\s+', ' ', regex=True)\n",
    "MReport2.feedback = MReport2.feedback.replace('\\s+', ' ', regex=True)\n",
    "MReport3.feedback = MReport3.feedback.replace('\\s+', ' ', regex=True)\n",
    "MReport4.feedback = MReport4.feedback.replace('\\s+', ' ', regex=True)\n",
    "MReport5.feedback = MReport5.feedback.replace('\\s+', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "MReport1.Answer_1 = MReport1.Answer_1.replace('Neutral/Suggestion', 'Suggestion', regex=True)\n",
    "MReport2.Answer_1 = MReport2.Answer_1.replace('Neutral/Suggestion', 'Suggestion', regex=True)\n",
    "MReport3.Answer_1 = MReport3.Answer_1.replace('Neutral/Suggestion', 'Suggestion', regex=True)\n",
    "MReport4.Answer_1 = MReport4.Answer_1.replace('Neutral/Suggestion', 'Suggestion', regex=True)\n",
    "MReport5.Answer_1 = MReport5.Answer_1.replace('Neutral/Suggestion', 'Suggestion', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "MReport1.to_csv(\"B.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "MReport11 = pd.DataFrame()\n",
    "MReport11[\"feedback\"]= MReport1[\"feedback\"]\n",
    "MReport11[\"sentiment\"]= MReport1[\"Answer_1\"]\n",
    "MReport11.to_csv(\"MReport11.csv\")\n",
    "\n",
    "MReport22 = pd.DataFrame()\n",
    "MReport22[\"feedback\"]= MReport2[\"feedback\"]\n",
    "MReport22[\"sentiment\"]= MReport2[\"Answer_1\"]\n",
    "MReport22.to_csv(\"MReport22.csv\")\n",
    "\n",
    "MReport33 = pd.DataFrame()\n",
    "MReport33[\"feedback\"]= MReport3[\"feedback\"]\n",
    "MReport33[\"sentiment\"]= MReport3[\"Answer_1\"]\n",
    "MReport33.to_csv(\"MReport33.csv\")\n",
    "\n",
    "MReport44 = pd.DataFrame()\n",
    "MReport44[\"feedback\"]= MReport4[\"feedback\"]\n",
    "MReport44[\"sentiment\"]= MReport4[\"Answer_1\"]\n",
    "MReport44.to_csv(\"MReport44.csv\")\n",
    "\n",
    "MReport55 = pd.DataFrame()\n",
    "MReport55[\"feedback\"]= MReport5[\"feedback\"]\n",
    "MReport55[\"sentiment\"]= MReport5[\"Answer_1\"]\n",
    "MReport55.to_csv(\"MReport55.csv\")\n",
    "\n",
    "New_MReport=pd.concat([MReport11,MReport22, MReport33, MReport44, MReport55])\n",
    "New_MReport.to_csv(\"New_MReport.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27790, 2)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_MReport.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=pd.concat([New_Dict,New_MReport])\n",
    "Train.to_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154862, 2)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Test data Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import1= pd.read_csv(\"/Users/kamakshibansal/Downloads/import.csv\")\n",
    "import2= pd.read_csv(\"/Users/kamakshibansal/Downloads/import3.csv\")\n",
    "import3= pd.read_csv(\"/Users/kamakshibansal/Downloads/import4.csv\")\n",
    "import4= pd.read_csv(\"/Users/kamakshibansal/Downloads/import5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import1.feedback = import1.feedback.replace('\\s+', ' ', regex=True)\n",
    "import2.feedback = import2.feedback.replace('\\s+', ' ', regex=True)\n",
    "import3.feedback = import3.feedback.replace('\\s+', ' ', regex=True)\n",
    "import4.feedback = import4.feedback.replace('\\s+', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import11 = pd.DataFrame()\n",
    "import11[\"feedback\"]= import1[\"feedback\"]\n",
    "\n",
    "import22 = pd.DataFrame()\n",
    "import22[\"feedback\"]= import2[\"feedback\"]\n",
    "\n",
    "import33 = pd.DataFrame()\n",
    "import33[\"feedback\"]= import3[\"feedback\"]\n",
    "\n",
    "import44 = pd.DataFrame()\n",
    "import44[\"feedback\"]= import4[\"feedback\"]\n",
    "\n",
    "Test=pd.concat([import11,import22, import33, import44])\n",
    "Test.to_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25629, 1)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning \n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopword(word):\n",
    "    return word not in words\n",
    " \n",
    "# StopWords Removed \n",
    "#Dictionary1['NewReviews'] = Dictionary1['feedback'].str.lower().str.split()\n",
    "Dictionary1['Feedback'] = (Dictionary1['feedback'].str.lower().str.split()).apply(lambda x : [item for item in x if item not in stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary1['Feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = 'english',\n",
    "    max_features = 85\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_data_features = vectorizer.fit_transform(Train.feedback.tolist() + Test.feedback.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180491, 85)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data_features_nd = corpus_data_features.toarray()\n",
    "corpus_data_features_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alway', 'ani', 'awesom', 'bad', 'befor', 'best', 'boy', 'brand', 'buy', 'colour', 'come', 'custom', 'day', 'deliv', 'deliveri', 'did', 'differ', 'easi', 'excel', 'exchang', 'execut', 'expect', 'experi', 'fast', 'fit', 'good', 'got', 'great', 'guy', 'ha', 'happi', 'improv', 'item', 'jabong', 'just', 'like', 'look', 'love', 'm', 'make', 'materi', 'money', 'myntra', 'n', 'need', 'nice', 'onli', 'order', 'pack', 'packag', 'perfect', 'person', 'pleas', 'polit', 'price', 'process', 'product', 'provid', 'qualiti', 'quick', 'realli', 'receiv', 'refund', 'return', 's', 'satisfi', 'servic', 'shirt', 'shoe', 'shop', 'shown', 'size', 't', 'thank', 'thi', 'time', 'tri', 'u', 'use', 'veri', 'wa', 'want', 'work', 'wrong', 'xxx']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print (vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4139 alway\n",
      "3381 ani\n",
      "5443 awesom\n",
      "3569 bad\n",
      "6397 befor\n",
      "5551 best\n",
      "7869 boy\n",
      "3401 brand\n",
      "4693 buy\n",
      "3541 colour\n",
      "3617 come\n",
      "6780 custom\n",
      "4921 day\n",
      "16961 deliv\n",
      "53695 deliveri\n",
      "5092 did\n",
      "3919 differ\n",
      "3030 easi\n",
      "6538 excel\n",
      "5320 exchang\n",
      "6872 execut\n",
      "4747 expect\n",
      "8230 experi\n",
      "7753 fast\n",
      "4846 fit\n",
      "52243 good\n",
      "5845 got\n",
      "6776 great\n",
      "5602 guy\n",
      "3819 ha\n",
      "12332 happi\n",
      "3244 improv\n",
      "5144 item\n",
      "5333 jabong\n",
      "3787 just\n",
      "8843 like\n",
      "4288 look\n",
      "7534 love\n",
      "4578 m\n",
      "2721 make\n",
      "3261 materi\n",
      "2943 money\n",
      "5375 myntra\n",
      "6600 n\n",
      "2867 need\n",
      "13072 nice\n",
      "3121 onli\n",
      "14526 order\n",
      "2860 pack\n",
      "3503 packag\n",
      "3068 perfect\n",
      "7737 person\n",
      "7138 pleas\n",
      "3670 polit\n",
      "5159 price\n",
      "3728 process\n",
      "56613 product\n",
      "2942 provid\n",
      "14869 qualiti\n",
      "3400 quick\n",
      "6124 realli\n",
      "7788 receiv\n",
      "5688 refund\n",
      "10867 return\n",
      "4518 s\n",
      "4879 satisfi\n",
      "25930 servic\n",
      "3210 shirt\n",
      "3739 shoe\n",
      "7777 shop\n",
      "2712 shown\n",
      "12488 size\n",
      "5274 t\n",
      "14053 thank\n",
      "14284 thi\n",
      "21342 time\n",
      "4410 tri\n",
      "4257 u\n",
      "3593 use\n",
      "38104 veri\n",
      "37433 wa\n",
      "3101 want\n",
      "3882 work\n",
      "2843 wrong\n",
      "10349 xxx\n"
     ]
    }
   ],
   "source": [
    "dist = np.sum(corpus_data_features_nd, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print (count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# remember that corpus_data_features_nd contains all of our original train and test data, so we need to exclude\n",
    "# the unlabeled test entries\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "    corpus_data_features_nd[0:len(Train)], \n",
    "    Train.sentiment,\n",
    "    train_size=0.85, \n",
    "    random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', ..., 'Positive', 'Positive',\n",
       "       'Positive'], dtype=object)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157124408092983"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics, cross_validation\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.78      0.74      0.76      7101\n",
      "   Positive       0.84      0.94      0.89     13996\n",
      " Suggestion       0.65      0.24      0.35      2133\n",
      "\n",
      "avg / total       0.80      0.82      0.80     23230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=corpus_data_features_nd[0:len(Train)], y=Train.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "test_pred = log_model.predict(corpus_data_features_nd[len(Train):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25629,)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test[\"sentiment\"]= test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.to_csv(\"Sentiment_Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "model= xgb.XGBClassifier(learning_rate =0.1,n_estimators=100,max_depth=5,min_child_weight=1,\n",
    " gamma=0,subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',nthread=4,scale_pos_weight=1,seed=27)\n",
    "model= model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', ..., 'Positive', 'Positive',\n",
       "       'Positive'], dtype=object)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169177787343952"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics, cross_validation\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
